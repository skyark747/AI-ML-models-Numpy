{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent \n",
    "\n",
    "def stochastic_gradient_descent(X,Y,epochs):\n",
    "  theta = np.zeros((X.shape[1],1))\n",
    "  alpha=0.01\n",
    "  prev_loss = float('inf')\n",
    "  threshold=1e-6\n",
    "  \n",
    "  for _ in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "      h=np.dot(X[i],theta)\n",
    "      error=h-Y[i]\n",
    "      R=np.dot(error,X[i])\n",
    "      theta=theta-alpha*R.T  \n",
    "\n",
    "    loss = L2_loss(Y,np.dot(X,theta))\n",
    "        \n",
    "    if abs(prev_loss - loss) < threshold:  \n",
    "        break\n",
    "        \n",
    "    prev_loss = loss \n",
    "\n",
    "  return theta\n",
    "\n",
    "def prediction(theta,X_test):\n",
    "   return np.dot(X_test,theta)\n",
    "\n",
    "def L2_loss(y_true,y_pred):\n",
    "  return np.mean(y_pred-y_true)**2\n",
    "\n",
    "\n",
    "def minmax_scaling(X):\n",
    "    min=np.min(X)\n",
    "    return (X-min)/max(X)-min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "\n",
    "df=pd.read_csv(\"path to dataset\")\n",
    "X=df['X1']\n",
    "Y=df['y']\n",
    "\n",
    "X=np.matrix(X).T\n",
    "Y=np.array(Y)\n",
    "X_scaled=minmax_scaling(X) #normalization \n",
    "X_scaled = np.c_[np.ones((len(X_scaled), 1)), X_scaled]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,Y,test_size=0.2)\n",
    "\n",
    "theta=stochastic_gradient_descent(X_train,y_train,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=prediction(theta,X_test)\n",
    "print(f\"error after prediction : {L2_loss(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting regression line\n",
    "\n",
    "train_features=np.array(X_train[:,1]) #plt takes array type as input not matrix\n",
    "\n",
    "plt.scatter(train_features,y_train,label='train samples')\n",
    "\n",
    "features=np.array(X_test[:,1]) \n",
    "\n",
    "plt.scatter(features,y_test,label='test samples')\n",
    "plt.plot(features,y_pred,color='black',label='regression line')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
