{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    np.random.seed(1)\n",
    "    return {\n",
    "        \"W1\": np.random.randn(input_size, hidden_size)*0.01,\n",
    "        \"b1\": np.zeros((1, hidden_size)),\n",
    "        \"W2\": np.random.randn(hidden_size, output_size)*0.01,\n",
    "        \"b2\": np.zeros((1, output_size)),\n",
    "    }\n",
    "\n",
    "def forward_pass(X, params, apply_dropout,is_training, keep_prob=0.8):\n",
    "    Z1 = np.dot(X, params[\"W1\"]) + params[\"b1\"]\n",
    "    A1 = sigmoid(Z1)\n",
    "    if apply_dropout or is_training:\n",
    "        dropout_mask = (np.random.rand(*A1.shape) < keep_prob).astype(float)\n",
    "        A1 *= dropout_mask\n",
    "    else:\n",
    "        A1*=keep_prob\n",
    "    Z2 = np.dot(A1, params[\"W2\"]) + params[\"b2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "    return A2, {\n",
    "        \"A1\": A1,\n",
    "        \"A2\": A2,\n",
    "        \"Z1\": Z1,\n",
    "        \"Z2\": Z2,\n",
    "        \"dropout_mask\": dropout_mask if apply_dropout else None,\n",
    "    }\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    eps = 1e-8\n",
    "    return -np.mean(y_true * np.log(y_pred + eps) + (1 - y_true) * np.log(1 - y_pred + eps))\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    predictions = (y_pred > 0.5).astype(int)\n",
    "    return np.mean(predictions == y_true) * 100\n",
    "\n",
    "def backward_pass(X, y, cache, params, learning_rate, keep_prob=1.0):\n",
    "    A1, A2 = cache[\"A1\"], cache[\"A2\"]\n",
    "    m = X.shape[0]\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    dA1 = np.dot(dZ2, params[\"W2\"].T)\n",
    "    dA1 *= sigmoid_derivative(A1)\n",
    "    if cache[\"dropout_mask\"] is not None:\n",
    "        dA1 *= cache[\"dropout_mask\"]\n",
    "    dW1 = np.dot(X.T, dA1) / m\n",
    "    db1 = np.sum(dA1, axis=0, keepdims=True) / m\n",
    "    params[\"W2\"] -= learning_rate * dW2\n",
    "    params[\"b2\"] -= learning_rate * db2\n",
    "    params[\"W1\"] -= learning_rate * dW1\n",
    "    params[\"b1\"] -= learning_rate * db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    X, y, hidden_size=10, epochs=100, learning_rate=0.1, keep_prob=0.8, patience=5\n",
    "):\n",
    "    input_size = X.shape[1]\n",
    "    output_size = 1\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    params = initialize_parameters(\n",
    "        input_size, hidden_size, output_size\n",
    "    )  \n",
    "    best_loss = float(\"inf\")\n",
    "    wait = 0\n",
    "    history = {\"loss\": [], \"acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred, cache = forward_pass(\n",
    "            X_train, params, apply_dropout=True,is_training=True, keep_prob=keep_prob\n",
    "        )  \n",
    "        loss = compute_loss(y_train, y_pred) \n",
    "        acc = compute_accuracy(y_train, y_pred) \n",
    "\n",
    "        backward_pass(\n",
    "            X_train, y_train, cache, params, learning_rate, keep_prob\n",
    "        )  \n",
    "\n",
    "        val_pred, _ = forward_pass(\n",
    "            X_val, params, apply_dropout=False,is_training=True\n",
    "        )  \n",
    "        val_loss = compute_loss(y_val, val_pred)\n",
    "        val_acc = compute_accuracy(\n",
    "            y_val, val_pred\n",
    "        )\n",
    "\n",
    "        history[\"loss\"].append(loss)\n",
    "        history[\"acc\"].append(acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    return params, history\n",
    "\n",
    "def test(X,params):\n",
    "\n",
    "    y_pred,_=forward_pass(X,params,apply_dropout=False,is_training=False)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Heart Disease Dataset (Cleaned version from UCI)\n",
    "def load_heart_data():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "    column_names = [\n",
    "        \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \n",
    "        \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "    ]\n",
    "    data = pd.read_csv(url, names=column_names, na_values=\"?\")\n",
    "    \n",
    "    # Preprocessing:\n",
    "    # 1. Convert target to binary (0 = no disease, 1 = disease)\n",
    "    data[\"target\"] = data[\"target\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # 2. Handle missing values (drop rows with NaN)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    # 3. Separate features (X) and labels (y)\n",
    "    X = data.drop(\"target\", axis=1).values\n",
    "    y = data[\"target\"].values.reshape(-1, 1)\n",
    "    \n",
    "    # 4. Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(epochs,training_loss,v_test_loss,training_acc,v_test_acc):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_loss, label='Train Loss')\n",
    "    plt.plot(v_test_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    #accuracy\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(training_acc, label='Train accuracy')\n",
    "    plt.plot(v_test_acc, label='Validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X,y=load_heart_data()\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training of the ann\n",
    "params, history = train(X_train, y_train, hidden_size=10, epochs=100, learning_rate=0.9, keep_prob=0.8, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training  vs validation\n",
    "epochs=100\n",
    "plot_history(epochs,history['loss'],history['val_loss'],history['acc'],history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing of ann\n",
    "y_pred=test(X_test,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "test_loss=compute_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "test_acc=compute_accuracy(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
