{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75465b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Preprocessing functions\n",
    "def tolowercase(text):\n",
    "    text=text.lower()\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    new_text=\"\"\n",
    "    for j in range(len(text)):\n",
    "        char=text[j]\n",
    "        if char.isalnum() or char == \" \":\n",
    "            new_text+=char\n",
    "    \n",
    "    return new_text\n",
    "        \n",
    "\n",
    "def remove_stop_words(tokens, stop_words_list):\n",
    "    for words in stop_words_list:\n",
    "        if words in tokens:\n",
    "            tokens.remove(words)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "   return text.split()\n",
    "\n",
    "def preprocess_text(text,stop_words):\n",
    "    text=tolowercase(text)\n",
    "    text=remove_punctuation(text)\n",
    "    tokens=tokenize(text)\n",
    "    tokens=remove_stop_words(tokens,stop_words_list=stop_words)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Part 2: Feature extraction\n",
    "def build_vocabulary(documents,stop_words):\n",
    "    vocabulary=set()\n",
    "    for text in documents:\n",
    "        tokens=preprocess_text(text,stop_words)\n",
    "        vocabulary.update(tokens)\n",
    "\n",
    "    vec=[*vocabulary]\n",
    "    return vec\n",
    "\n",
    "def create_bow_vector(document, vocabulary):\n",
    "    bgw=[]\n",
    "    \n",
    "    for text in document:\n",
    "        vec=[0]*len(vocabulary)\n",
    "        tokens=tokenize(text)\n",
    "        for word in tokens:\n",
    "            if word in vocabulary:\n",
    "                i=vocabulary.index(word)\n",
    "                vec[i]+=1\n",
    "                \n",
    "        bgw.append(vec)\n",
    "\n",
    "    return bgw\n",
    "\n",
    "\n",
    "def convert_to_binary_features(bow_vectors):\n",
    "    \"\"\"Convert count features to binary features (0/1 for word presence/absence)\"\"\"\n",
    "    \n",
    "    for features in bow_vectors:\n",
    "        for i in range(len(features)):\n",
    "            if features[i]>=1:\n",
    "                features[i]=1\n",
    "            \n",
    "    return bow_vectors\n",
    "\n",
    "\n",
    "\n",
    "def preprocessing(X,stop_words):\n",
    "    vocabulary=build_vocabulary(X,stop_words)\n",
    "    bgw=create_bow_vector(X,vocabulary)\n",
    "    bgw=convert_to_binary_features(bgw)\n",
    "    return bgw,vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_entropy(Y):\n",
    "    count=Counter(Y)\n",
    "    P=[]\n",
    "    for i in count.values():\n",
    "        P.append(i/len(Y))\n",
    "    P=np.array(P)\n",
    "    return -np.sum(np.dot(P,np.log2(P)))\n",
    "\n",
    "\n",
    "def calculate_gini(Y):\n",
    "    \"\"\"Calculate Gini impurity for a set of labels\"\"\"\n",
    "    count=Counter(Y)\n",
    "    P=[]\n",
    "    for i in count.values():\n",
    "        P.append(i/len(Y))\n",
    "    P=np.array(P)\n",
    "\n",
    "    return 1-np.sum(P**2)\n",
    "\n",
    "\n",
    "def calculate_information_gain(parent, left_child, right_child):\n",
    "    \"\"\"Calculate information gain for a split\"\"\"\n",
    "    Ep=calculate_gini(parent)    \n",
    "    left_w=len(left_child)/parent.shape[0]\n",
    "    right_w=len(right_child)/parent.shape[0]\n",
    "    Ec=(left_w*calculate_gini(left_child)+right_w*calculate_gini(right_child))/2\n",
    "\n",
    "    return Ep-Ec\n",
    "\n",
    "\n",
    "def split(X,Y):\n",
    "\n",
    "    for j in range(X.shape[1]):\n",
    "        thresholds=np.unique(X[:,j]) #get all unique values as thresholds\n",
    "\n",
    "    max_IG=float('-inf')\n",
    "    left_split,right_split=[],[]\n",
    "    left_split_l,right_split_l=[],[]\n",
    "    best_feature_index,best_threshold=0,0\n",
    "\n",
    "    for j in range(X.shape[1]):\n",
    "        \n",
    "            \n",
    "        for threshold in thresholds:\n",
    "            \n",
    "            Left,Right=[],[]\n",
    "            Left_l,Right_l=[],[]\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                    if X[i,j]<= threshold:\n",
    "                        Left.append(X[i])\n",
    "                        Left_l.append(Y[i])\n",
    "                    else:\n",
    "                        Right.append(X[i])\n",
    "                        Right_l.append(Y[i])\n",
    "    \n",
    "\n",
    "            IG=calculate_information_gain(Y,Left_l,Right_l)\n",
    "            if  IG>max_IG:\n",
    "                max_IG=IG\n",
    "                left_split,right_split=Left,Right\n",
    "                left_split_l,right_split_l=Left_l,Right_l\n",
    "                best_feature_index=j\n",
    "                best_threshold=threshold\n",
    "            \n",
    "\n",
    "    return left_split,right_split,left_split_l,right_split_l,best_feature_index,best_threshold\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6005a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self,threshold=None,label=None,feature_index=None):\n",
    "\n",
    "        # node values to store\n",
    "        self.feature_index=feature_index\n",
    "        self.threshold=threshold\n",
    "        self.label=label # label for leaf node for prediction\n",
    "\n",
    "        #pointers\n",
    "        self.left=None\n",
    "        self.right=None\n",
    "\n",
    "\n",
    "def build_tree(depth,n,X,Y):\n",
    "    if len(Y) == 0:\n",
    "        return None\n",
    "    \n",
    "    if all(Y==Y[0]) or Y.shape[0]==1:\n",
    "        return DecisionTree(label=Y[0]) # check if all labels are same\n",
    "    \n",
    "    if depth==n:\n",
    "        return DecisionTree(label=np.bincount(Y).argmax()) #returning the most common label\n",
    "    \n",
    "    left,right,left_l,right_l,feature_index,threshold=split(X,Y)\n",
    "\n",
    "    \n",
    "\n",
    "    node=DecisionTree(feature_index=feature_index,threshold=threshold)\n",
    "\n",
    "    node.left=build_tree(depth+1,n,np.array(left),np.array(left_l))\n",
    "    node.right=build_tree(depth+1,n,np.array(right),np.array(right_l))\n",
    "\n",
    "    return node\n",
    "\n",
    "\n",
    "def get_feature_importance(tree, feature_names,importance):\n",
    "    \"\"\"Identify important features based on tree structure\"\"\"\n",
    "    \n",
    "    if tree.left==None or tree.right==None:\n",
    "        return importance\n",
    "\n",
    "    feature = feature_names[tree.feature_index]\n",
    "    importance.append(feature)  \n",
    "\n",
    "    get_feature_importance(tree.left, feature_names, importance)\n",
    "    get_feature_importance(tree.right, feature_names, importance)\n",
    "\n",
    "    return importance\n",
    "\n",
    "\n",
    "def train(X,Y,max_depth):\n",
    "    return build_tree(0,max_depth,X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bacb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(X,Node):\n",
    "    if Node.left==None or Node.right==None:\n",
    "        return Node.label\n",
    "    \n",
    "    if X[Node.feature_index]<=Node.threshold:\n",
    "        return predict(X,Node.left)\n",
    "    else:\n",
    "        return predict(X,Node.right)\n",
    "    \n",
    "\n",
    "def prediction(X,Tree):\n",
    "    result_arr=[]\n",
    "    for i in range(len(X)):\n",
    "        result=predict(X[i],Tree)\n",
    "        result_arr.append(int(result))\n",
    "    return result_arr\n",
    "\n",
    "def accurracy(y_pred,y_true):\n",
    "    return np.mean(y_pred==y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data \n",
    "sample_positive = [\n",
    "    \"i love this product it works great\",\n",
    "    \"excellent service and fast delivery\",\n",
    "    \"best purchase i have made this year\",\n",
    "    \"very happy with the quality of this item\",\n",
    "    \"the customer service was amazing and helpful\",\n",
    "    \"works perfectly and arrived on time\",\n",
    "    \"exceeded my expectations highly recommend\",\n",
    "    \"easy to use and does exactly what it says\",\n",
    "    \"great value for money will buy again\",\n",
    "    \"fantastic product and excellent experience\"\n",
    "]\n",
    "\n",
    "sample_negative = [\n",
    "    \"terrible experience would not recommend\",\n",
    "    \"product broke after two days\",\n",
    "    \"customer service was unhelpful and rude\",\n",
    "    \"waste of money does not work properly\", \n",
    "    \"extremely disappointed with this purchase\",\n",
    "    \"arrived late and damaged\",\n",
    "    \"did not match the description at all\",\n",
    "    \"poor quality and overpriced\",\n",
    "    \"worst product i have ever bought\",\n",
    "    \"completely useless and frustrating\"\n",
    "]\n",
    "\n",
    "# A minimal stop words list\n",
    "stop_words = [\"the\", \"a\", \"an\", \"and\", \"or\", \"but\", \"is\", \"are\", \"was\", \"were\", \n",
    "              \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"this\", \"that\", \"have\", \"has\"]\n",
    "\n",
    "\n",
    "\n",
    "X=sample_positive+sample_negative\n",
    "\n",
    "X,vocabulary=preprocessing(X,stop_words)\n",
    "\n",
    "labels = [0] * len(sample_positive) + [1] * len(sample_positive)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,labels,test_size=0.2)\n",
    "\n",
    "X_train=np.atleast_2d(X_train)\n",
    "X_test=np.atleast_2d(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5268e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training for decision tree\n",
    "\n",
    "Tree=train(X_train,y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67495f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=[]\n",
    "importance=get_feature_importance(Tree,vocabulary,importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff83493",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the tree\n",
    "\n",
    "y_pred=prediction(X_test,Tree)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32201e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy \n",
    "acc=accurracy(y_pred,y_test)\n",
    "print(f\"accurracy is {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing decision tree\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_edges(nx_tree,node,parent=None,edge_label=\"\"):\n",
    "    if node is None:\n",
    "        return\n",
    "    \n",
    "    if node.label is not None:\n",
    "        node_label = f\"Label: {node.label}\"\n",
    "    else:\n",
    "        node_label = f\"{node.feature_index} <= {node.threshold}\"\n",
    "\n",
    "    nx_tree.add_node(id(node), label=node_label)\n",
    "\n",
    "    if parent is not None:\n",
    "        nx_tree.add_edge(parent, id(node), label=edge_label)\n",
    "\n",
    "    add_edges(nx_tree, node.left, id(node), \"Yes\")\n",
    "    add_edges(nx_tree, node.right, id(node), \"No\")\n",
    "    \n",
    "def draw_tree(Tree):\n",
    "    nx_tree=nx.DiGraph()\n",
    "    add_edges(nx_tree,Tree)\n",
    "    pos = nx.spring_layout(nx_tree)  \n",
    "    labels = nx.get_node_attributes(nx_tree, \"label\")\n",
    "    edge_labels = nx.get_edge_attributes(nx_tree, \"label\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    nx.draw(nx_tree, pos, with_labels=True, labels=labels, node_size=3000, node_color=\"lightblue\", edge_color=\"black\")\n",
    "    nx.draw_networkx_edge_labels(nx_tree, pos, edge_labels=edge_labels)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_tree(Tree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
